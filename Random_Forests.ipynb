{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forests.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYRF4CwdRche"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAjp8Dh9RlIa"
      },
      "source": [
        "**Random Forests**\n",
        "\n",
        "In previous lessons we've covered the basics of decision trees and bootstrap aggregating, but in this lesson, we'll turn our spotlight solely on Random Forests.\n",
        "\n",
        "*Why Random Forests?*\n",
        "\n",
        "  A random forest uses the age old saying \"two (or more) heads are better\" than one and applies it to decsion trees. We saw that a decision tree splits the dataset on various features and that it's essential to place priority on feature splits that best seperate the dataset.\n",
        "\n",
        "Even though they are widely applicable and easy to visualize, *decision trees have their downsides*:\n",
        "- At *high depths*, they can create unnecessarily complex trees that *overfit* the data.\n",
        "- Can be very unpredictable when slightly changing up the dataset.\n",
        "- Since decision trees rely on *heuristics* (basically a user defined metric to say how well the tree is splitting up the dataset) those heuristics can't be guaranteed to always find the optimum tree.\n",
        "\n",
        "These above problems that a single decision tree faces can be mitigated by a little help from its friends... more decision trees!\n",
        "\n",
        "Essentially a random forest divys up the tasks of finding the best features to split on among different decision trees and let's them run their course on these features. After some defined time to stop, the trees congregate together in an *ensemble* to compare their findings and find an average feature split that works best off of what they've found.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdCLqqflWcP7"
      },
      "source": [
        "*Let's Explore This Forest! But, First, A Little Recap*\n",
        "\n",
        "I know, I want to get right to creating these strange things called Random Forests too, but we need to take a step back and make sure we understand how decision trees work.\n",
        "\n",
        "--------------------- CREATE FUNCTIONS FOR GINI IMPURITY, ENTROPY ------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA4puQpqPtmq"
      },
      "source": [
        "probs = [.13, .37, .19, .31]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmgB4tZOP-lv"
      },
      "source": [
        "def gini_impurity(probs):\n",
        "  ## -- TO DO -- ##\n",
        "  out = 0.0\n",
        "  hmm = sum()\n",
        "  return hmm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW8Xz_tMQT9b",
        "outputId": "d07a8373-147e-45ca-8f04-f5b53f3094bb"
      },
      "source": [
        "impurity = gini_impurity(probabilities)\n",
        "print(impurities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1131, 0.2331, 0.1539, 0.21389999999999998]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD5YHh9r7Zee"
      },
      "source": [
        "--------------------- INTRODUCTION TO DATABASE + LINK ------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7gybxg9WyNC"
      },
      "source": [
        "Let's first import this dataset, and see how we can divide our MPG values into classes to get the ball (or wheel) rolling!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "1T5qHqoYWzIl",
        "outputId": "48624fd8-1e08-41c2-847e-6e813bd094a2"
      },
      "source": [
        "#import the auto-mpg csv in using pandas\n",
        "cars = pd.read_csv(\"auto-mpg.csv\")\n",
        "\n",
        "## TO DO ##\n",
        "## Plot the mpg values using pandas as a histogram ##\n",
        "cars.mpg.plot(kind='hist')\n",
        "\n",
        "mpg_max = max(cars.mpg)\n",
        "mpg_min = min(cars.mpg)\n",
        "print(\"Largest (Most Efficient) MPG: \", mpg_max) ## SHOULD EQUAL 46.6\n",
        "print(\"Smallest (Least Efficient) MPG: \", mpg_min) ## SHOULD EQUAL 9.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largest (Most Efficient) MPG:  46.6\n",
            "Smallest (Least Efficient) MPG:  9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O043aeuCaN2f"
      },
      "source": [
        "What did you find as the largest and smallest miles per gallons?\n",
        "\n",
        "As we can see, there's quite a range in MPG that a car could have. They are also skewed to one side.\n",
        "\n",
        "To make our process easier, lets divide our data up into four named categories, depending on the range of MPGs it falls under and how much we'd want to buy it.\n",
        "- **0:**  (5.0 < MPG <= 14.9)\n",
        "- **1:**  (15.0 < MPG <= 24.9)\n",
        "- **2:**  (25.0 < MPG <= 34.9)\n",
        "- **3:**  ( 35.0 < MPG <= 50.0)\n",
        "\n",
        "\n",
        "Let's now create a **desirability** array from the MPG column of the **cars** dataset, where if the MPG falls into a certain value range as specified above, we insert the corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNNiwBp1X2eg"
      },
      "source": [
        "# Should return an array containing the desirability ranking deduced from the mpg \n",
        "# cars_dataset: \n",
        "def desire_creator(cars_dataset):\n",
        "  desires = []\n",
        "  ## -- TO DO -- ##\n",
        "  for mpg in np.asarray(cars_dataset.mpg):\n",
        "    if (mpg > 5.0 and mpg <= 14.9):\n",
        "      desires.append(0)\n",
        "    elif (mpg >= 15.0 and mpg <= 24.9):\n",
        "      desires.append(1)\n",
        "    elif (mpg >= 25.0 and mpg <= 34.9):\n",
        "      desires.append(2)\n",
        "    elif (mpg >= 35.0 and mpg <= 50.0):\n",
        "      desires.append(3)\n",
        "    else:\n",
        "      raise Exception(\"Unexpected MPG:\", mpg)\n",
        "    ## -- END -- ##\n",
        "  return np.asarray(desires)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP4mdGBoT4Cm"
      },
      "source": [
        "desirability = desire_creator(cars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhDlOsudiTGZ"
      },
      "source": [
        "------ CODE FOR HISTOGRAM OF THE DESIRABILITIES AND THEIR COUNTS -------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lbe0RxJiaiy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_T24lsXid5O"
      },
      "source": [
        "Let's create a new dataset named **cars_and_desires** replacing the **mpg** column with **desirability**.\n",
        "\n",
        "Since sklearn's random tree classifier only works numeric data, we'll have to drop the **car name** and **horspepower** columns, since they are *string* and *object* types respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unuBC9ldkHWW"
      },
      "source": [
        "## -- TO DO: -- ##\n",
        "cars_and_desires = cars.copy()\n",
        "cars_and_desires.columns\n",
        "cars_and_desires = cars_and_desires.drop(['mpg'], axis=1)\n",
        "cars_and_desires = cars_and_desires.drop(['car name'], axis=1)\n",
        "cars_and_desires = cars_and_desires.drop(['horsepower'], axis=1)\n",
        "cars_and_desires['desirability'] = desirability\n",
        "## -- END -- ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "eEM1p6CCk1jw",
        "outputId": "d83ed504-3a0d-4d82-c916-2ba89661f1b7"
      },
      "source": [
        "cars_and_desires"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>desirability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>2790</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2130</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>2295</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>2625</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>2720</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cylinders  displacement  weight  ...  model year  origin  desirability\n",
              "0            8         307.0    3504  ...          70       1             1\n",
              "1            8         350.0    3693  ...          70       1             1\n",
              "2            8         318.0    3436  ...          70       1             1\n",
              "3            8         304.0    3433  ...          70       1             1\n",
              "4            8         302.0    3449  ...          70       1             1\n",
              "..         ...           ...     ...  ...         ...     ...           ...\n",
              "393          4         140.0    2790  ...          82       1             2\n",
              "394          4          97.0    2130  ...          82       2             3\n",
              "395          4         135.0    2295  ...          82       1             2\n",
              "396          4         120.0    2625  ...          82       1             2\n",
              "397          4         119.0    2720  ...          82       1             2\n",
              "\n",
              "[398 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AsqLygfQN44"
      },
      "source": [
        "Now that we have our data/attributes and labels together... the only logical thing to do now is split them apart.\n",
        "\n",
        "We need to make our data X and our features y, to then train our random forest. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m2iMaz_Qkyl"
      },
      "source": [
        "# Splits the dataset into an X of the data/attributes, and y of the features on a given index.\n",
        "# dataset: incoming dataset to be split\n",
        "# index: the index of final column that is be split off to create the features\n",
        "def data_label_splitter(dataset, index):\n",
        "  ## -- TO DO -- ##\n",
        "  X = cars_and_desires.iloc[:, 0:index]\n",
        "  y = cars_and_desires.iloc[:, index] \n",
        "  ## -- END -- ##\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7PDeForSkqs"
      },
      "source": [
        "Let's now fil in this function to divide our X and y into test trains splits.\n",
        "\n",
        "# *Hint:* Look at the imports at the top of the page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTA_8ASfSrSZ"
      },
      "source": [
        "# Splits the dataset into testing and training data:\n",
        "# X: The data matrix\n",
        "# y: The labels column\n",
        "# test_fraction: What fraction (float) of the data will go to the test set\n",
        "def train_test_splitter(X, y, test_fraction):\n",
        "  ##-- TO DO --##\n",
        "  return train_test_split(X, y, test_size=test_fraction, random_state = 0)\n",
        "  ## -- END -- ##\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-YKUdzWYgAo"
      },
      "source": [
        "I know filling out these functions is annoying -- they'll come in handy later, I swear. Fill in the method parameters below. Let's first have our testing data to be $\\frac{2}{10}$ of the overall dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVFTAibSWagR"
      },
      "source": [
        "test_fraction = 0.2 ## Assign fraction value\n",
        "X, y = data_label_splitter(cars_and_desires, 6) ## Fill in method parameter\n",
        "X_train, X_test, y_train, y_test = test_train_splitter(X, y, test_fraction) ## Fill in method parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjaqTZbnN5u5"
      },
      "source": [
        "Ok, so now we finally have our test and training data set up. All we have to do is create a Decision Tree Classifier and see how it does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIKe7qAH-xuK",
        "outputId": "a2d689f0-7214-4b0d-d038-ef16b168ceb7"
      },
      "source": [
        "tree_classifier = DecisionTreeClassifier(random_state=0) ## To Fill In\n",
        "tree_classifier.fit(X_train, y_train) # To Fill in \n",
        "tree_y_pred = tree_classifier.predict(X_test) #To Fill in \n",
        "\n",
        "print(classification_report(y_test, tree_y_pred))\n",
        "print(accuracy_score(y_test,tree_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.60      0.55        10\n",
            "           1       0.82      0.68      0.74        40\n",
            "           2       0.63      0.90      0.75        21\n",
            "           3       0.80      0.44      0.57         9\n",
            "\n",
            "    accuracy                           0.70        80\n",
            "   macro avg       0.69      0.66      0.65        80\n",
            "weighted avg       0.73      0.70      0.70        80\n",
            "\n",
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_G8TMAWPTUs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub_-gwl6AGdX",
        "outputId": "5cb72168-ff8d-41c2-fb08-ba04d97bc6bb"
      },
      "source": [
        "forest_classifier = RandomForestClassifier(n_estimators=500)\n",
        "forest_classifier.fit(X_train, y_train)\n",
        "forest_y_pred = forest_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_test, forest_y_pred))\n",
        "print(accuracy_score(y_test, forest_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.90      0.78        10\n",
            "           1       0.91      0.72      0.81        40\n",
            "           2       0.58      0.90      0.70        21\n",
            "           3       1.00      0.22      0.36         9\n",
            "\n",
            "    accuracy                           0.74        80\n",
            "   macro avg       0.79      0.69      0.66        80\n",
            "weighted avg       0.80      0.74      0.73        80\n",
            "\n",
            "0.7375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxyIlVMWJv9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}